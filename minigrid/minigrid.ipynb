{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x7W68dxl9O85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/rjy/anaconda3/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /Users/rjy/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/rjy/anaconda3/lib/python3.11/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/rjy/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/rjy/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/rjy/anaconda3/lib/python3.11/site-packages (from torch) (2023.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: gymnasium in /Users/rjy/anaconda3/lib/python3.11/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium) (4.7.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: minigrid in /Users/rjy/anaconda3/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from minigrid) (1.24.3)\n",
      "Requirement already satisfied: gymnasium>=0.28.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from minigrid) (0.29.1)\n",
      "Requirement already satisfied: pygame>=2.4.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from minigrid) (2.5.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium>=0.28.1->minigrid) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium>=0.28.1->minigrid) (4.7.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium>=0.28.1->minigrid) (0.0.4)\n",
      "Requirement already satisfied: rl_zoo3 in /Users/rjy/anaconda3/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: sb3-contrib<3.0,>=2.2.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from rl_zoo3) (2.2.1)\n",
      "Requirement already satisfied: gymnasium~=0.29.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from rl_zoo3) (0.29.1)\n",
      "Requirement already satisfied: huggingface-sb3<4.0,>=3.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from rl_zoo3) (3.0)\n",
      "Requirement already satisfied: tqdm in /Users/rjy/anaconda3/lib/python3.11/site-packages (from rl_zoo3) (4.65.0)\n",
      "Requirement already satisfied: rich in /Users/rjy/anaconda3/lib/python3.11/site-packages (from rl_zoo3) (13.7.0)\n",
      "Requirement already satisfied: optuna>=3.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from rl_zoo3) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from rl_zoo3) (6.0)\n",
      "Requirement already satisfied: pytablewriter~=1.2 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from rl_zoo3) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium~=0.29.1->rl_zoo3) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium~=0.29.1->rl_zoo3) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium~=0.29.1->rl_zoo3) (4.7.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from gymnasium~=0.29.1->rl_zoo3) (0.0.4)\n",
      "Requirement already satisfied: huggingface-hub~=0.8 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from huggingface-sb3<4.0,>=3.0->rl_zoo3) (0.19.4)\n",
      "Requirement already satisfied: wasabi in /Users/rjy/anaconda3/lib/python3.11/site-packages (from huggingface-sb3<4.0,>=3.0->rl_zoo3) (1.1.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from optuna>=3.0->rl_zoo3) (1.13.0)\n",
      "Requirement already satisfied: colorlog in /Users/rjy/anaconda3/lib/python3.11/site-packages (from optuna>=3.0->rl_zoo3) (6.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from optuna>=3.0->rl_zoo3) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from optuna>=3.0->rl_zoo3) (1.4.39)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from pytablewriter~=1.2->rl_zoo3) (68.0.0)\n",
      "Requirement already satisfied: DataProperty<2,>=1.0.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from pytablewriter~=1.2->rl_zoo3) (1.0.1)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from pytablewriter~=1.2->rl_zoo3) (1.1.3)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from pytablewriter~=1.2->rl_zoo3) (3.2.0)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from pytablewriter~=1.2->rl_zoo3) (1.3.3)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from pytablewriter~=1.2->rl_zoo3) (0.1.4)\n",
      "Requirement already satisfied: typepy[datetime]<2,>=1.3.2 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from pytablewriter~=1.2->rl_zoo3) (1.3.2)\n",
      "Requirement already satisfied: stable-baselines3<3.0,>=2.2.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from sb3-contrib<3.0,>=2.2.1->rl_zoo3) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from rich->rl_zoo3) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from rich->rl_zoo3) (2.15.1)\n",
      "Requirement already satisfied: Mako in /Users/rjy/anaconda3/lib/python3.11/site-packages (from alembic>=1.5.0->optuna>=3.0->rl_zoo3) (1.3.0)\n",
      "Requirement already satisfied: filelock in /Users/rjy/anaconda3/lib/python3.11/site-packages (from huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (2023.12.0)\n",
      "Requirement already satisfied: requests in /Users/rjy/anaconda3/lib/python3.11/site-packages (from huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (2.31.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->rl_zoo3) (0.1.0)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter~=1.2->rl_zoo3) (4.0.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from sqlalchemy>=1.3.0->optuna>=3.0->rl_zoo3) (2.0.1)\n",
      "Requirement already satisfied: torch>=1.13 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (2.1.0)\n",
      "Requirement already satisfied: pandas in /Users/rjy/anaconda3/lib/python3.11/site-packages (from stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (1.5.3)\n",
      "Requirement already satisfied: matplotlib in /Users/rjy/anaconda3/lib/python3.11/site-packages (from stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (3.7.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.9 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.8.0->typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3) (1.16.0)\n",
      "Requirement already satisfied: sympy in /Users/rjy/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/rjy/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna>=3.0->rl_zoo3) (2.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rjy/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.13->stable-baselines3<3.0,>=2.2.1->sb3-contrib<3.0,>=2.2.1->rl_zoo3) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install gymnasium\n",
    "!pip install minigrid\n",
    "!pip install rl_zoo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lzOqvnaL9Tvj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import minigrid\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obs(obs):\n",
    "    mat = obs['image']\n",
    "    mat = mat[:, :, 0].transpose((1, 0))\n",
    "\n",
    "    res = ''\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            res += str(mat[i, j])\n",
    "            res += ' '\n",
    "        res += '\\n'\n",
    "    res += '\\n'\n",
    "    res = res[:-2]\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ont_hot(mat):\n",
    "    mat = mat.transpose((1, 0, 2))\n",
    "    \n",
    "    res = ''\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            for k in range(9):\n",
    "                if mat[i, j, k] > 0:\n",
    "                    res += str(k)\n",
    "                    res += ' '\n",
    "        res += '\\n'\n",
    "    res += '\\n'\n",
    "    res = res[:-2]\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wuR1oC4cIUCs"
   },
   "outputs": [],
   "source": [
    "def compute_score(task, policy):\n",
    "  num_episodes = 10\n",
    "  cur_episode  = 0\n",
    "\n",
    "  seed_by_episode = [42, 34, 50, 1, 9, 7, 43, 56, 90, 11]\n",
    "  score_by_episode = np.zeros(num_episodes)\n",
    "\n",
    "  while cur_episode < num_episodes:\n",
    "\n",
    "    cumulative_reward = 0\n",
    "    cur_seed = seed_by_episode[cur_episode]\n",
    "\n",
    "    observation, info = task.reset(seed=cur_seed)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "      action = policy(observation)\n",
    "      observation, reward, terminated, truncated, info = task.step(action)\n",
    "      cumulative_reward += reward\n",
    "\n",
    "      if terminated or truncated:\n",
    "        done = True\n",
    "        score_by_episode[cur_episode] = cumulative_reward\n",
    "        cur_episode += 1\n",
    "\n",
    "  score_mean = round(score_by_episode.mean(), 3)\n",
    "  score_std  = round(score_by_episode.std(), 3)\n",
    "  score_best = round(score_by_episode.max(), 3)\n",
    "\n",
    "  print(f\"Best score: {score_best}\")\n",
    "  print(f\"Average score: {score_mean, score_std}\")\n",
    "\n",
    "  return score_by_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Customize Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "I carefully read through all the wrappers in https://github.com/Farama-Foundation/Minigrid/blob/master/minigrid/wrappers.py and gained a lot of inspiration.\n",
    "\n",
    "About `DiscreteObsWrapper`:\n",
    "\n",
    "- The `DictObservationSpaceWrapper` suggested that I could remove the tuples `(object, color, state)` unrelated to these three tasks to reduce the state space, allowing us to obtain some discrete values (approximately 9).\n",
    "\n",
    "- The `OneHotPartialObsWrapper` suggested that I could one-hot encode the discrete values, resulting in an image of shape `(7, 7, 9)`.\n",
    "\n",
    "- Then, based on this image, I proceeded with subsequent CNN operations.\n",
    "\n",
    "---\n",
    "\n",
    "About `ActionReward`:\n",
    "\n",
    "- I have looked into **Reward Shaping**, but I'm not sure how to integrate it with this task. \n",
    "\n",
    "- As a tentative solution, I have written an `ActionReward` to incentivize successful subtasks, addressing the issue of having to complete the entire task to receive a **non-zero** reward originally.\n",
    "\n",
    "- The reward brought by sub-tasks is given by $(1 - 0.9 \\times \\frac{\\text{step count}}{\\text{max steps}}) \\times \\left(1 - \\frac{2}{3}^{\\text{|sub-tasks|}} \\right)$. It ensures that the overall reward remains within the range $[0, \\text{reward})$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wrappers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile wrappers.py\n",
    "\n",
    "import numpy as np\n",
    "from gymnasium.core import ObservationWrapper, Wrapper\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class DiscreteObsWrapper(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=1,\n",
    "            shape=(7, 7, 9),\n",
    "            dtype=\"uint8\",\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def encode_image(cls, image: np.ndarray):\n",
    "        OBJECT_TO_IDX = {\n",
    "            \"unseen\": 0,\n",
    "            \"empty\": 1,\n",
    "            \"wall\": 2,\n",
    "            \"floor\": 3,\n",
    "            \"door\": 4,\n",
    "            \"key\": 5,\n",
    "            \"ball\": 6,\n",
    "            \"box\": 7,\n",
    "            \"goal\": 8,\n",
    "            \"lava\": 9,\n",
    "            \"agent\": 10,\n",
    "        }\n",
    "\n",
    "        STATE_TO_IDX = {\n",
    "            \"open\": 0,\n",
    "            \"closed\": 1,\n",
    "            \"locked\": 2,\n",
    "        }\n",
    "\n",
    "        # 0: unseen\n",
    "        # 1: empty\n",
    "        # 2: wall\n",
    "        # 3-5: door * state\n",
    "        # 6: key\n",
    "        # 7: box\n",
    "        # 8: ball\n",
    "\n",
    "        rows = []\n",
    "        for i in range(7):\n",
    "            row = []\n",
    "            for j in range(7):\n",
    "                (obj, color, state) = image[i][j]\n",
    "                item = -1\n",
    "                if obj == OBJECT_TO_IDX['unseen']:\n",
    "                    assert color == 0\n",
    "                    assert state == 0\n",
    "                    item = 0\n",
    "                elif obj == OBJECT_TO_IDX['empty']:\n",
    "                    assert color == 0\n",
    "                    assert state == 0\n",
    "                    item = 1\n",
    "                elif obj == OBJECT_TO_IDX['wall']:\n",
    "                    assert color == 5\n",
    "                    assert state == 0\n",
    "                    item = 2\n",
    "                elif obj == OBJECT_TO_IDX['door']:\n",
    "                    assert color < 6, f'Unknown Color ({color})'\n",
    "                    item = 3 + state\n",
    "                elif obj == OBJECT_TO_IDX['key']:\n",
    "                    assert color < 6, f'Unknown Color ({color})'\n",
    "                    assert state == 0\n",
    "                    item = 6\n",
    "                elif obj == OBJECT_TO_IDX['box']:\n",
    "                    assert color < 6, f'Unknown Color ({color})'\n",
    "                    assert state == 0\n",
    "                    item = 7\n",
    "                elif obj == OBJECT_TO_IDX['ball']:\n",
    "                    assert color < 6, f'Unknown Color ({color})'\n",
    "                    assert state == 0\n",
    "                    item = 8\n",
    "                else:\n",
    "                    assert False, f'Unknown Object ({obj})'\n",
    "                row.append(\n",
    "                    cls.one_hot_item(item, 9)\n",
    "                )\n",
    "            rows.append(row)\n",
    "        image_array = np.array(rows)\n",
    "        return image_array\n",
    "\n",
    "    @classmethod\n",
    "    def one_hot_item(cls, ith: int, n: int):\n",
    "        one_hot_array = np.zeros(\n",
    "            shape=(n,), dtype=\"uint8\"\n",
    "        )\n",
    "        one_hot_array[ith] = 1\n",
    "        return one_hot_array\n",
    "\n",
    "    def observation(self, obs):\n",
    "        image = obs[\"image\"]\n",
    "        image_array = self.encode_image(image)\n",
    "        return image_array\n",
    "\n",
    "\n",
    "class ActionReward(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"A wrapper that adds an exploration bonus to less visited positions.\n",
    "\n",
    "        Args:\n",
    "            env: The environment to apply the wrapper\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.met_key = False\n",
    "        self.met_door = False\n",
    "        self.met_ball = False\n",
    "        self.met_box = False\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Steps through the environment with `action`.\"\"\"\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        \n",
    "        front = obs['image'][3, 5]\n",
    "        obj, color, state = front\n",
    "\n",
    "        # Map of object type to integers\n",
    "        OBJECT_TO_IDX = {\n",
    "            \"unseen\": 0,\n",
    "            \"empty\": 1,\n",
    "            \"wall\": 2,\n",
    "            \"floor\": 3,\n",
    "            \"door\": 4,\n",
    "            \"key\": 5,\n",
    "            \"ball\": 6,\n",
    "            \"box\": 7,\n",
    "            \"goal\": 8,\n",
    "            \"lava\": 9,\n",
    "            \"agent\": 10,\n",
    "        }\n",
    "\n",
    "        # Map of state names to integers\n",
    "        STATE_TO_IDX = {\n",
    "            \"open\": 0,\n",
    "            \"closed\": 1,\n",
    "            \"locked\": 2,\n",
    "        }\n",
    "\n",
    "        if self.met_key and obj == OBJECT_TO_IDX[\"key\"]:\n",
    "            self.met_key = True\n",
    "        if self.met_door and obj == OBJECT_TO_IDX[\"door\"]:\n",
    "            self.met_door = True\n",
    "        if self.met_ball and obj == OBJECT_TO_IDX[\"ball\"]:\n",
    "            self.met_ball = True\n",
    "        if self.met_box and obj == OBJECT_TO_IDX[\"box\"]:\n",
    "            self.met_box = True\n",
    "\n",
    "        counter = 0.\n",
    "        if self.met_key:\n",
    "            counter += 1\n",
    "        if self.met_door:\n",
    "            counter += 1\n",
    "        if self.met_ball:\n",
    "            counter += 0.5\n",
    "        if self.met_box:\n",
    "            counter += 1.5\n",
    "\n",
    "        done = terminated or truncated\n",
    "        if done:\n",
    "            self.met_key = False\n",
    "            self.met_door = False\n",
    "            self.met_ball = False\n",
    "            self.met_box = False\n",
    "\n",
    "        if not done or reward == 0.:\n",
    "            reward = 1 - 0.9 * (self.step_count / self.max_steps)\n",
    "            reward = reward * (1 - 2/3 ** counter)\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        return obs, info \n",
    "\n",
    "\n",
    "\n",
    "__all__  = [\n",
    "    'DiscreteObsWrapper',\n",
    "    'ActionReward',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was inspired by the work at https://github.com/lcswillems/rl-starter-files/blob/master/model.py#L27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile models.py\n",
    "\n",
    "from typing import Dict, List, Tuple, Type, Union\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MinigridFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.Space, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the original `features_extractor_class` in `CnnPolicy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting policies.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile policies.py\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo.policies import CnnPolicy\n",
    "\n",
    "from models import MinigridFeaturesExtractor\n",
    "\n",
    "\n",
    "class MinigridCnnPolicy(CnnPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            features_extractor_class=MinigridFeaturesExtractor,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "PPO.policy_aliases[\"MinigridCnnPolicy\"] = MinigridCnnPolicy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all configurations for my hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reward.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile reward.yaml\n",
    "\n",
    "# Following https://github.com/lcswillems/rl-starter-files\n",
    "MiniGrid-Empty-Random-5x5-v0: &minigrid-defaults\n",
    "  env_wrapper: minigrid.wrappers.FlatObsWrapper # See GH/1320#issuecomment-1421108191\n",
    "  normalize: true\n",
    "  n_envs: 8  # number of environment copies running in parallel\n",
    "  n_timesteps: !!float 1e5\n",
    "  n_steps: 128  # batch size is n_steps * n_env\n",
    "  batch_size: 64  # Number of training minibatches per update\n",
    "  gae_lambda: 0.95  #  Factor for trade-off of bias vs variance for Generalized Advantage Estimator\n",
    "  gamma: 0.99\n",
    "  n_epochs: 10  # Number of epoch when optimizing the surrogate\n",
    "  ent_coef: 0.0  # Entropy coefficient for the loss caculation\n",
    "  learning_rate: 2.5e-4  # The learning rate, it can be a function\n",
    "  clip_range: 0.2  # Clipping parameter, it can be a function\n",
    "  policy: 'MlpPolicy'\n",
    "  policy_kwargs: \"dict(\n",
    "    normalize_images=False,\n",
    "  )\"\n",
    "\n",
    "\n",
    "MiniGrid-Unlock-v0:\n",
    "  <<: *minigrid-defaults\n",
    "  n_timesteps: !!float 1e5\n",
    "\n",
    "  env_wrapper:\n",
    "    - wrappers.ActionReward\n",
    "    - wrappers.DiscreteObsWrapper\n",
    "  policy: 'policies.MinigridCnnPolicy'\n",
    "  policy_kwargs: \"dict(\n",
    "    normalize_images=False,\n",
    "    net_arch=dict(pi=[64], vf=[64]),\n",
    "  )\"\n",
    "\n",
    "\n",
    "MiniGrid-UnlockPickup-v0:\n",
    "  <<: *minigrid-defaults\n",
    "  n_timesteps: !!float 1e5\n",
    "\n",
    "  env_wrapper:\n",
    "    - wrappers.ActionReward\n",
    "    - wrappers.DiscreteObsWrapper\n",
    "  policy: 'policies.MinigridCnnPolicy'\n",
    "  policy_kwargs: \"dict(\n",
    "    normalize_images=False,\n",
    "    net_arch=dict(pi=[64], vf=[64]),\n",
    "  )\"\n",
    "\n",
    "\n",
    "MiniGrid-BlockedUnlockPickup-v0:\n",
    "  <<: *minigrid-defaults\n",
    "  n_timesteps: !!float 1e5\n",
    "\n",
    "  env_wrapper:\n",
    "    - wrappers.ActionReward\n",
    "    - wrappers.DiscreteObsWrapper\n",
    "  policy: 'policies.MinigridCnnPolicy'\n",
    "  policy_kwargs: \"dict(\n",
    "    normalize_images=False,\n",
    "    net_arch=dict(pi=[64], vf=[64]),\n",
    "  )\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting without-reward.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile without-reward.yaml\n",
    "\n",
    "# Following https://github.com/lcswillems/rl-starter-files\n",
    "MiniGrid-Empty-Random-5x5-v0: &minigrid-defaults\n",
    "  env_wrapper: minigrid.wrappers.FlatObsWrapper # See GH/1320#issuecomment-1421108191\n",
    "  normalize: true\n",
    "  n_envs: 8  # number of environment copies running in parallel\n",
    "  n_timesteps: !!float 1e5\n",
    "  n_steps: 128  # batch size is n_steps * n_env\n",
    "  batch_size: 64  # Number of training minibatches per update\n",
    "  gae_lambda: 0.95  #  Factor for trade-off of bias vs variance for Generalized Advantage Estimator\n",
    "  gamma: 0.99\n",
    "  n_epochs: 10  # Number of epoch when optimizing the surrogate\n",
    "  ent_coef: 0.0  # Entropy coefficient for the loss caculation\n",
    "  learning_rate: 2.5e-4  # The learning rate, it can be a function\n",
    "  clip_range: 0.2  # Clipping parameter, it can be a function\n",
    "  policy: 'MlpPolicy'\n",
    "  policy_kwargs: \"dict(\n",
    "    normalize_images=False,\n",
    "  )\"\n",
    "\n",
    "\n",
    "MiniGrid-Unlock-v0:\n",
    "  <<: *minigrid-defaults\n",
    "  n_timesteps: !!float 1e5\n",
    "\n",
    "  env_wrapper:\n",
    "    - wrappers.DiscreteObsWrapper\n",
    "  policy: 'policies.MinigridCnnPolicy'\n",
    "  policy_kwargs: \"dict(\n",
    "    normalize_images=False,\n",
    "    net_arch=dict(pi=[64], vf=[64]),\n",
    "  )\"\n",
    "\n",
    "\n",
    "MiniGrid-UnlockPickup-v0:\n",
    "  <<: *minigrid-defaults\n",
    "  n_timesteps: !!float 3e5\n",
    "\n",
    "  env_wrapper:\n",
    "    - wrappers.DiscreteObsWrapper\n",
    "  policy: 'policies.MinigridCnnPolicy'\n",
    "  policy_kwargs: \"dict(\n",
    "    normalize_images=False,\n",
    "    net_arch=dict(pi=[64], vf=[64]),\n",
    "  )\"\n",
    "\n",
    "\n",
    "MiniGrid-BlockedUnlockPickup-v0:\n",
    "  <<: *minigrid-defaults\n",
    "  n_timesteps: !!float 3e5\n",
    "\n",
    "  env_wrapper:\n",
    "    - wrappers.DiscreteObsWrapper\n",
    "  policy: 'policies.MinigridCnnPolicy'\n",
    "  policy_kwargs: \"dict(\n",
    "    normalize_images=False,\n",
    "    net_arch=dict(pi=[64], vf=[64]),\n",
    "  )\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTrpMlHvGYp6"
   },
   "source": [
    "## Point 1.1\n",
    "Solve the [Minigrid Unlock](https://minigrid.farama.org/environments/minigrid/UnlockEnv/) task.\n",
    "\n",
    "\n",
    "![](https://minigrid.farama.org/_images/UnlockEnv.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DMnOrnBuRkc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MiniGrid-Unlock-v0 ==========\n",
      "Seed: 4191266599\n",
      "Loading hyperparameters from: reward.yaml\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 64),\n",
      "             ('clip_range', 0.2),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('env_wrapper',\n",
      "              ['wrappers.ActionReward', 'wrappers.DiscreteObsWrapper']),\n",
      "             ('gae_lambda', 0.95),\n",
      "             ('gamma', 0.99),\n",
      "             ('learning_rate', 0.00025),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 10),\n",
      "             ('n_steps', 128),\n",
      "             ('n_timesteps', 100000.0),\n",
      "             ('normalize', True),\n",
      "             ('policy', 'policies.MinigridCnnPolicy'),\n",
      "             ('policy_kwargs',\n",
      "              'dict( normalize_images=False, net_arch=dict(pi=[64], vf=[64]), '\n",
      "              ')')])\n",
      "Using 8 environments\n",
      "Creating test environment\n",
      "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
      "Normalization activated: {'gamma': 0.99}\n",
      "Using cpu device\n",
      "Log path: logs/ppo/MiniGrid-Unlock-v0_3\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.step_count to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.step_count` for environment variables or `env.get_wrapper_attr('step_count')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.max_steps to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.max_steps` for environment variables or `env.get_wrapper_attr('max_steps')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1271 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 1024 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 444          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085231885 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.0525      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00112     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 1.66         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 287       |\n",
      "|    ep_rew_mean          | 0.0152    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 369       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 8         |\n",
      "|    total_timesteps      | 3072      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0183073 |\n",
      "|    clip_fraction        | 0.174     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.93     |\n",
      "|    explained_variance   | -3.56     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.0713   |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -0.0351   |\n",
      "|    value_loss           | 0.0322    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 287         |\n",
      "|    ep_rew_mean          | 0.0152      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 344         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012543411 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.271      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.0784      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 0.00762     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 329         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018601894 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -1.41       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.075      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 0.0195      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 0.00762     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016786221 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -0.134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0567     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 0.0637      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 0.00508     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019379556 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.915      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0551     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 0.0197      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 0.00508     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021534357 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.234      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0651     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0549     |\n",
      "|    value_loss           | 0.0437      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 0.00381     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018704642 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.111      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.000601   |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 0.0264      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 288.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 288         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023159277 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -2.13       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0713     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0509     |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.step_count to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.step_count` for environment variables or `env.get_wrapper_attr('step_count')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.max_steps to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.max_steps` for environment variables or `env.get_wrapper_attr('max_steps')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 288      |\n",
      "|    ep_rew_mean     | 0.00381  |\n",
      "| time/              |          |\n",
      "|    fps             | 290      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 288        |\n",
      "|    ep_rew_mean          | 0.00381    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 11264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02278438 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.83      |\n",
      "|    explained_variance   | -0.25      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0762    |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0476    |\n",
      "|    value_loss           | 0.0263     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 0.00305     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018150944 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -1.28       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 0.0112      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 0.00305     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019333538 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0506     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0506     |\n",
      "|    value_loss           | 0.0626      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 0.00254     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020699903 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -0.576      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0371     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 0.00254     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021465652 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -0.0544     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0536     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    value_loss           | 0.0827      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 288        |\n",
      "|    ep_rew_mean          | 0.00218    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 297        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02350596 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.77      |\n",
      "|    explained_variance   | -0.666     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0445    |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0458    |\n",
      "|    value_loss           | 0.0175     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 0.00218     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021394186 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.08       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0574     |\n",
      "|    value_loss           | 0.0346      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 286         |\n",
      "|    ep_rew_mean          | 0.0125      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022127056 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -0.528      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00241    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0518     |\n",
      "|    value_loss           | 0.0276      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 286         |\n",
      "|    ep_rew_mean          | 0.0125      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017836286 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -0.144      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00488    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.11 +/- 0.23\n",
      "Episode length: 258.40 +/- 59.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 258         |\n",
      "|    mean_reward          | 0.113       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020156406 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.0551      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0585     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 0.0378      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 283      |\n",
      "|    ep_rew_mean     | 0.0243   |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 283         |\n",
      "|    ep_rew_mean          | 0.0229      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023313705 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -0.0686     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 283         |\n",
      "|    ep_rew_mean          | 0.0217      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018865531 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | -0.696      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0451     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    value_loss           | 0.0612      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 281         |\n",
      "|    ep_rew_mean          | 0.0319      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023963569 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | -0.174      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0353     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 0.0375      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 279        |\n",
      "|    ep_rew_mean          | 0.0387     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02474666 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.67      |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.00398   |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0459    |\n",
      "|    value_loss           | 0.118      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 279         |\n",
      "|    ep_rew_mean          | 0.037       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016958855 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.0822      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 0.079       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 279         |\n",
      "|    ep_rew_mean          | 0.0399      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024702623 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -0.804      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0679     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0542     |\n",
      "|    value_loss           | 0.0574      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 278         |\n",
      "|    ep_rew_mean          | 0.0431      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021748804 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00727    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 278         |\n",
      "|    ep_rew_mean          | 0.0445      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028131234 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0401     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    value_loss           | 0.075       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 278         |\n",
      "|    ep_rew_mean          | 0.0429      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023833293 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.00527     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.08 +/- 0.16\n",
      "Episode length: 268.20 +/- 39.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 268         |\n",
      "|    mean_reward          | 0.0819      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027957806 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.0419      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.041      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0581     |\n",
      "|    value_loss           | 0.0757      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 276      |\n",
      "|    ep_rew_mean     | 0.0496   |\n",
      "| time/              |          |\n",
      "|    fps             | 279      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 274         |\n",
      "|    ep_rew_mean          | 0.057       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023667414 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0402     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    value_loss           | 0.098       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 273         |\n",
      "|    ep_rew_mean          | 0.0611      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020869408 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0697     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 273         |\n",
      "|    ep_rew_mean          | 0.0611      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021412514 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0375     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 0.0765      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 272         |\n",
      "|    ep_rew_mean          | 0.0662      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022263736 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -0.431      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0578     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0468     |\n",
      "|    value_loss           | 0.0663      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 271         |\n",
      "|    ep_rew_mean          | 0.0713      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026397467 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 0.0996      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 271         |\n",
      "|    ep_rew_mean          | 0.0713      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021013992 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 271         |\n",
      "|    ep_rew_mean          | 0.0713      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024281409 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.285      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0401     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 0.0532      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 270         |\n",
      "|    ep_rew_mean          | 0.0748      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020883176 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -0.314      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0255     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 0.0598      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 268         |\n",
      "|    ep_rew_mean          | 0.0824      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025089018 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.00452     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 0.0715      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.30 +/- 0.38\n",
      "Episode length: 203.60 +/- 105.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 204         |\n",
      "|    mean_reward          | 0.304       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027359713 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0508     |\n",
      "|    value_loss           | 0.0848      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 268      |\n",
      "|    ep_rew_mean     | 0.0838   |\n",
      "| time/              |          |\n",
      "|    fps             | 284      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 143      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 265        |\n",
      "|    ep_rew_mean          | 0.0952     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 41984      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02313238 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.54      |\n",
      "|    explained_variance   | -0.0829    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0122    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0437    |\n",
      "|    value_loss           | 0.0679     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 265        |\n",
      "|    ep_rew_mean          | 0.0964     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02502209 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | 0.457      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0762     |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0373    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 265         |\n",
      "|    ep_rew_mean          | 0.0951      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019589718 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.0689      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 258       |\n",
      "|    ep_rew_mean          | 0.121     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 283       |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 158       |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0215556 |\n",
      "|    clip_fraction        | 0.254     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.56     |\n",
      "|    explained_variance   | 0.248     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.0292    |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | -0.0394   |\n",
      "|    value_loss           | 0.122     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 253         |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024929885 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.051      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 247         |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024888938 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0429      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 0.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 245         |\n",
      "|    ep_rew_mean          | 0.169       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028778857 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0411     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0497     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 232         |\n",
      "|    ep_rew_mean          | 0.216       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025351582 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0257      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 0.315       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.77 +/- 0.14\n",
      "Episode length: 73.60 +/- 45.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.6        |\n",
      "|    mean_reward          | 0.77        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025944453 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0321      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 221      |\n",
      "|    ep_rew_mean     | 0.256    |\n",
      "| time/              |          |\n",
      "|    fps             | 284      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 176      |\n",
      "|    total_timesteps | 50176    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 211         |\n",
      "|    ep_rew_mean          | 0.293       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027139734 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.000888    |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0522     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 180         |\n",
      "|    ep_rew_mean          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028503962 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.083       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 0.294       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 159        |\n",
      "|    ep_rew_mean          | 0.479      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 186        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03077766 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.48      |\n",
      "|    explained_variance   | 0.562      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0793     |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.0587    |\n",
      "|    value_loss           | 0.322      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | 0.585       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029553054 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.00604     |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0513     |\n",
      "|    value_loss           | 0.293       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 97.5      |\n",
      "|    ep_rew_mean          | 0.689     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 286       |\n",
      "|    iterations           | 54        |\n",
      "|    time_elapsed         | 192       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0324862 |\n",
      "|    clip_fraction        | 0.313     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.46     |\n",
      "|    explained_variance   | 0.49      |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.0495    |\n",
      "|    n_updates            | 530       |\n",
      "|    policy_gradient_loss | -0.0561   |\n",
      "|    value_loss           | 0.291     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.8        |\n",
      "|    ep_rew_mean          | 0.764       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029244266 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0297      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0569     |\n",
      "|    value_loss           | 0.271       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 53.8      |\n",
      "|    ep_rew_mean          | 0.832     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 288       |\n",
      "|    iterations           | 56        |\n",
      "|    time_elapsed         | 198       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0360376 |\n",
      "|    clip_fraction        | 0.39      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.41     |\n",
      "|    explained_variance   | 0.437     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.0235   |\n",
      "|    n_updates            | 550       |\n",
      "|    policy_gradient_loss | -0.0595   |\n",
      "|    value_loss           | 0.234     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.3        |\n",
      "|    ep_rew_mean          | 0.88        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034403898 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.000993    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.057      |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | 0.902       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037980426 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.029      |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0617     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.92 +/- 0.03\n",
      "Episode length: 24.80 +/- 8.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 24.8        |\n",
      "|    mean_reward          | 0.923       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036936946 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.037      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0613     |\n",
      "|    value_loss           | 0.0874      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.2     |\n",
      "|    ep_rew_mean     | 0.918    |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 209      |\n",
      "|    total_timesteps | 60416    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 20.6       |\n",
      "|    ep_rew_mean          | 0.936      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 212        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03623317 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0.434      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0684    |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.056     |\n",
      "|    value_loss           | 0.0682     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.8        |\n",
      "|    ep_rew_mean          | 0.941       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034427665 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.927      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0644     |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0499     |\n",
      "|    value_loss           | 0.0527      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.1        |\n",
      "|    ep_rew_mean          | 0.937       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039237596 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.835      |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0777     |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0552     |\n",
      "|    value_loss           | 0.0345      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 19.2       |\n",
      "|    ep_rew_mean          | 0.94       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 222        |\n",
      "|    total_timesteps      | 64512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03613907 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.789     |\n",
      "|    explained_variance   | 0.593      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0486    |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0546    |\n",
      "|    value_loss           | 0.0381     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.9        |\n",
      "|    ep_rew_mean          | 0.947       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036513932 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.048      |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0469     |\n",
      "|    value_loss           | 0.0367      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.1        |\n",
      "|    ep_rew_mean          | 0.947       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033371717 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.634      |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0663     |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0534     |\n",
      "|    value_loss           | 0.0209      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.5        |\n",
      "|    ep_rew_mean          | 0.945       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035795502 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.654      |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0571     |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 0.0339      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16          |\n",
      "|    ep_rew_mean          | 0.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035940126 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0111     |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 0.0285      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17          |\n",
      "|    ep_rew_mean          | 0.947       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035990514 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.604      |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0473     |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 0.0267      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 14.40 +/- 3.67\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 14.4       |\n",
      "|    mean_reward          | 0.955      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 70000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05011691 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.605     |\n",
      "|    explained_variance   | 0.589      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0734    |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.0496    |\n",
      "|    value_loss           | 0.0256     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 15       |\n",
      "|    ep_rew_mean     | 0.953    |\n",
      "| time/              |          |\n",
      "|    fps             | 291      |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 242      |\n",
      "|    total_timesteps | 70656    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.5        |\n",
      "|    ep_rew_mean          | 0.952       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037744343 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.555      |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0453     |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 0.0249      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.9        |\n",
      "|    ep_rew_mean          | 0.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036390122 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.519      |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0601     |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0476     |\n",
      "|    value_loss           | 0.0201      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 14.8       |\n",
      "|    ep_rew_mean          | 0.954      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 252        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04269109 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.453     |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0501    |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | -0.0401    |\n",
      "|    value_loss           | 0.0173     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 12.8       |\n",
      "|    ep_rew_mean          | 0.96       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 74752      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03037433 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.414     |\n",
      "|    explained_variance   | 0.51       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0109    |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.0355    |\n",
      "|    value_loss           | 0.0179     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.5        |\n",
      "|    ep_rew_mean          | 0.958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043018974 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.385      |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0425     |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.4        |\n",
      "|    ep_rew_mean          | 0.958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043408796 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.42       |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00261    |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.0157      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 13.3       |\n",
      "|    ep_rew_mean          | 0.959      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 266        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03466296 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.365     |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0418    |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.0372    |\n",
      "|    value_loss           | 0.0122     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.8        |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034111846 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.371      |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0408     |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 0.0163      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 12.9       |\n",
      "|    ep_rew_mean          | 0.96       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03041423 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.337     |\n",
      "|    explained_variance   | 0.64       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0532    |\n",
      "|    n_updates            | 770        |\n",
      "|    policy_gradient_loss | -0.0323    |\n",
      "|    value_loss           | 0.0071     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.96 +/- 0.02\n",
      "Episode length: 14.20 +/- 5.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 14.2       |\n",
      "|    mean_reward          | 0.956      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 80000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04314678 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.36      |\n",
      "|    explained_variance   | 0.689      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0519    |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | -0.0378    |\n",
      "|    value_loss           | 0.00847    |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.7     |\n",
      "|    ep_rew_mean     | 0.957    |\n",
      "| time/              |          |\n",
      "|    fps             | 292      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 276      |\n",
      "|    total_timesteps | 80896    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 12.6       |\n",
      "|    ep_rew_mean          | 0.961      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 280        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05032111 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.351     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0466    |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.0387    |\n",
      "|    value_loss           | 0.0104     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.2        |\n",
      "|    ep_rew_mean          | 0.962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033992175 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0423     |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 0.00703     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.7        |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020464897 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0457     |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.00772     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.9        |\n",
      "|    ep_rew_mean          | 0.963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025608933 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0432     |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.0133      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.9        |\n",
      "|    ep_rew_mean          | 0.963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032820575 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0305     |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.00643     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 12.2       |\n",
      "|    ep_rew_mean          | 0.962      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 85         |\n",
      "|    time_elapsed         | 298        |\n",
      "|    total_timesteps      | 87040      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04493284 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.668      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0513    |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | -0.0355    |\n",
      "|    value_loss           | 0.00685    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 12.2       |\n",
      "|    ep_rew_mean          | 0.962      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 302        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03436375 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.273     |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0543    |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.0336    |\n",
      "|    value_loss           | 0.00539    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.9       |\n",
      "|    ep_rew_mean          | 0.963      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 305        |\n",
      "|    total_timesteps      | 89088      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03249213 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.712      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0664    |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.0449    |\n",
      "|    value_loss           | 0.00622    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.96 +/- 0.02\n",
      "Episode length: 13.40 +/- 5.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13.4        |\n",
      "|    mean_reward          | 0.958       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036079906 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0421     |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 0.006       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.9     |\n",
      "|    ep_rew_mean     | 0.963    |\n",
      "| time/              |          |\n",
      "|    fps             | 290      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 309      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.6        |\n",
      "|    ep_rew_mean          | 0.964       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033932436 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0507     |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.00603     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.7       |\n",
      "|    ep_rew_mean          | 0.966      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03664448 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.267     |\n",
      "|    explained_variance   | 0.747      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0665    |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    value_loss           | 0.00472    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.4        |\n",
      "|    ep_rew_mean          | 0.961       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033003986 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0468     |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.00362     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.3        |\n",
      "|    ep_rew_mean          | 0.962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052732695 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0442     |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 0.0136      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.7       |\n",
      "|    ep_rew_mean          | 0.967      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 328        |\n",
      "|    total_timesteps      | 95232      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03374438 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.248     |\n",
      "|    explained_variance   | 0.65       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0466    |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | -0.0347    |\n",
      "|    value_loss           | 0.00943    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 13.1      |\n",
      "|    ep_rew_mean          | 0.959     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 289       |\n",
      "|    iterations           | 94        |\n",
      "|    time_elapsed         | 332       |\n",
      "|    total_timesteps      | 96256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0264466 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.283    |\n",
      "|    explained_variance   | 0.586     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.0414   |\n",
      "|    n_updates            | 930       |\n",
      "|    policy_gradient_loss | -0.0267   |\n",
      "|    value_loss           | 0.00574   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 11.2      |\n",
      "|    ep_rew_mean          | 0.965     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 289       |\n",
      "|    iterations           | 95        |\n",
      "|    time_elapsed         | 336       |\n",
      "|    total_timesteps      | 97280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0780054 |\n",
      "|    clip_fraction        | 0.278     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.363    |\n",
      "|    explained_variance   | 0.728     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.0657   |\n",
      "|    n_updates            | 940       |\n",
      "|    policy_gradient_loss | -0.0458   |\n",
      "|    value_loss           | 0.00764   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.3        |\n",
      "|    ep_rew_mean          | 0.962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027956218 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0476     |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.00501     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.8        |\n",
      "|    ep_rew_mean          | 0.963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049941666 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0518     |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    value_loss           | 0.0115      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 11.40 +/- 2.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 11.4        |\n",
      "|    mean_reward          | 0.964       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029542597 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0149     |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 0.00584     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 12.2     |\n",
      "|    ep_rew_mean     | 0.962    |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 347      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Saving to logs/ppo/MiniGrid-Unlock-v0_3\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-Unlock-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --conf-file reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 279, in <module>\r\n",
      "    train()\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 192, in train\r\n",
      "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\r\n",
      "AssertionError: The trained_agent must be a valid path to a .zip file\r\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-Unlock-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-Unlock-v0_1/MiniGrid-Unlock-v0.zip \\\n",
    "    --conf-file without-reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Nl2sT6CY9aac"
   },
   "outputs": [],
   "source": [
    "first_task = gym.make(\"MiniGrid-Unlock-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/Users/rjy/anaconda3/lib/python3.11/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/Users/rjy/anaconda3/lib/python3.11/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/Users/rjy/anaconda3/lib/python3.11/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from wrappers import DiscreteObsWrapper, ActionReward\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "first_env = DiscreteObsWrapper(first_task)\n",
    "first_model = PPO.load(\"logs/ppo/MiniGrid-Unlock-v0_2/best_model.zip\")\n",
    "\n",
    "def first_policy(observation):\n",
    "    observation = first_env.observation(observation)\n",
    "    action, _ = first_model.predict(observation)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BGLjI_m_KzxF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.984\n",
      "Average score: (0.877, 0.192)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.85, 0.93, 0.88, 0.97, 0.97, 0.98, 0.97, 0.32, 0.96, 0.93])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(task=first_task, policy=first_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMduj9WOQ6sa"
   },
   "source": [
    "## Point 1.2\n",
    "Solve the [Minigrid Unlock and Pickup](https://minigrid.farama.org/environments/minigrid/UnlockEnv/) task.\n",
    "\n",
    "![](https://minigrid.farama.org/_images/UnlockPickupEnv.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CsSmtYonI_SQ"
   },
   "outputs": [],
   "source": [
    "second_task = gym.make(\"MiniGrid-UnlockPickup-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 \n",
      "2 2 2 2 4 2 0 \n",
      "2 1 5 1 1 2 0 \n",
      "2 1 1 1 1 2 0 \n",
      "2 1 1 1 1 2 0 \n",
      "2 1 1 1 1 2 0 \n"
     ]
    }
   ],
   "source": [
    "print_obs(second_task.reset()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 \n",
      "2 2 2 2 4 2 0 \n",
      "2 1 5 1 1 2 0 \n",
      "2 1 1 1 1 2 0 \n",
      "2 1 1 1 1 2 0 \n",
      "2 1 1 1 1 2 0 \n"
     ]
    }
   ],
   "source": [
    "print_obs(second_task.step(5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2JJeQFWxQ2pS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 279, in <module>\r\n",
      "    train()\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 192, in train\r\n",
      "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\r\n",
      "AssertionError: The trained_agent must be a valid path to a .zip file\r\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-UnlockPickup-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-Unlock-v0_1/best_model.zip \\\n",
    "    --conf-file reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 279, in <module>\r\n",
      "    train()\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 192, in train\r\n",
      "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\r\n",
      "AssertionError: The trained_agent must be a valid path to a .zip file\r\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-UnlockPickup-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-UnlockPickup-v0_1/best_model.zip \\\n",
    "    --conf-file reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 279, in <module>\r\n",
      "    train()\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 192, in train\r\n",
      "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\r\n",
      "AssertionError: The trained_agent must be a valid path to a .zip file\r\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-UnlockPickup-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-UnlockPickup-v0_2/best_model.zip \\\n",
    "    --conf-file reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 279, in <module>\r\n",
      "    train()\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 192, in train\r\n",
      "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\r\n",
      "AssertionError: The trained_agent must be a valid path to a .zip file\r\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-UnlockPickup-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-UnlockPickup-v0_3/MiniGrid-UnlockPickup-v0.zip \\\n",
    "    --conf-file without-reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Avl9WIB0Rq1B"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/Users/rjy/anaconda3/lib/python3.11/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/Users/rjy/anaconda3/lib/python3.11/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/Users/rjy/anaconda3/lib/python3.11/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from wrappers import DiscreteObsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "second_env = DiscreteObsWrapper(second_task)\n",
    "second_model = PPO.load(\"logs/ppo/MiniGrid-UnlockPickup-v0_4/best_model.zip\")\n",
    "\n",
    "def second_policy(observation):\n",
    "  # print_obs(observation)\n",
    "  observation = second_env.observation(observation)\n",
    "  # print('-----------')\n",
    "  # print_ont_hot(observation)\n",
    "  action, _ = second_model.predict(observation)\n",
    "  # print(f'action: {action}\\n')\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "iEn_LFsSRDGs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.819\n",
      "Average score: (0.316, 0.329)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.49, 0.67, 0.00, 0.00, 0.00, 0.82, 0.47, 0.00, 0.00, 0.70])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(task=second_task, policy=second_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75UWdKFjRKuI"
   },
   "source": [
    "## Point 1.3\n",
    "Solve the [Minigrid Blocked, Unlock and Pickup](https://minigrid.farama.org/environments/minigrid/UnlockEnv/) task.\n",
    "\n",
    "![](https://minigrid.farama.org/_images/BlockedUnlockPickupEnv.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FXJA2lxeRvQI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MiniGrid-BlockedUnlockPickup-v0 ==========\n",
      "Seed: 3314051353\n",
      "Loading hyperparameters from: reward.yaml\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 64),\n",
      "             ('clip_range', 0.2),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('env_wrapper',\n",
      "              ['wrappers.ActionReward', 'wrappers.DiscreteObsWrapper']),\n",
      "             ('gae_lambda', 0.95),\n",
      "             ('gamma', 0.99),\n",
      "             ('learning_rate', 0.00025),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 10),\n",
      "             ('n_steps', 128),\n",
      "             ('n_timesteps', 100000.0),\n",
      "             ('normalize', True),\n",
      "             ('policy', 'policies.MinigridCnnPolicy'),\n",
      "             ('policy_kwargs',\n",
      "              'dict( normalize_images=False, net_arch=dict(pi=[64], vf=[64]), '\n",
      "              ')')])\n",
      "Using 8 environments\n",
      "Creating test environment\n",
      "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
      "Normalization activated: {'gamma': 0.99}\n",
      "Loading pretrained agent\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/Users/rjy/anaconda3/lib/python3.11/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/Users/rjy/anaconda3/lib/python3.11/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/Users/rjy/anaconda3/lib/python3.11/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "Log path: logs/ppo/MiniGrid-BlockedUnlockPickup-v0_7\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.step_count to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.step_count` for environment variables or `env.get_wrapper_attr('step_count')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.max_steps to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.max_steps` for environment variables or `env.get_wrapper_attr('max_steps')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 830  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 1024 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032786343 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.53       |\n",
      "|    explained_variance   | -0.00061    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 2.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040165193 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | -1.2        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.019      |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.0436      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013689893 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.562      |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0983      |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.0124      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011211497 |\n",
      "|    clip_fraction        | 0.0714      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    value_loss           | 0.00436     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 576        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10039801 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.673     |\n",
      "|    explained_variance   | 0.447      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.071     |\n",
      "|    n_updates            | 3650       |\n",
      "|    policy_gradient_loss | -0.048     |\n",
      "|    value_loss           | 0.0595     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030075882 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | -0.161      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0401     |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.0218      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025794357 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.00774     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015331073 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0509     |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    value_loss           | 0.00352     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 576         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013967678 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.675      |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00856    |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.00459     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.step_count to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.step_count` for environment variables or `env.get_wrapper_attr('step_count')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/rjy/anaconda3/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.max_steps to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.max_steps` for environment variables or `env.get_wrapper_attr('max_steps')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 232      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 576        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 11264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02392716 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.716     |\n",
      "|    explained_variance   | -0.248     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0164    |\n",
      "|    n_updates            | 3700       |\n",
      "|    policy_gradient_loss | -0.0267    |\n",
      "|    value_loss           | 0.0249     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016901555 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.015       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0154     |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.00901     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014214781 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.678      |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0254     |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.00185     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017542396 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0329     |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.00315     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034042653 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.785      |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0181     |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.0506      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021667609 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.779      |\n",
      "|    explained_variance   | -0.28       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.047      |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.0147      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006172967 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.678      |\n",
      "|    explained_variance   | -0.115      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.00448     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008035598 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.651      |\n",
      "|    explained_variance   | -0.388      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0205     |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    value_loss           | 0.00238     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 576          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 19456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049472824 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.649       |\n",
      "|    explained_variance   | 0.00661      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00118      |\n",
      "|    n_updates            | 3780         |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 0.00713      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.18 +/- 0.24\n",
      "Episode length: 485.20 +/- 127.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 485         |\n",
      "|    mean_reward          | 0.182       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024109123 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.0858      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0295     |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.0263      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 227      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 89       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027893048 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018471804 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.771      |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.00238     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 576        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 23552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02296365 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.767     |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0346    |\n",
      "|    n_updates            | 3820       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    value_loss           | 0.00481    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.075694874 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.933      |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 0.058       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016973028 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.959      |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0463     |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 0.0126      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 573         |\n",
      "|    ep_rew_mean          | 0.00739     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023547333 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.86       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.051      |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.00395     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 573          |\n",
      "|    ep_rew_mean          | 0.00632      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 231          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151969325 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.871       |\n",
      "|    explained_variance   | -0.0776      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0315      |\n",
      "|    n_updates            | 3860         |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    value_loss           | 0.0609       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 563         |\n",
      "|    ep_rew_mean          | 0.024       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023059104 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.891      |\n",
      "|    explained_variance   | -0.169      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0724     |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.0557     |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 563        |\n",
      "|    ep_rew_mean          | 0.024      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 128        |\n",
      "|    total_timesteps      | 29696      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06000278 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.869     |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0148     |\n",
      "|    n_updates            | 3880       |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    value_loss           | 0.0729     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 576         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044644497 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | -0.708      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.058      |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 0.0094      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 563      |\n",
      "|    ep_rew_mean     | 0.024    |\n",
      "| time/              |          |\n",
      "|    fps             | 221      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 138      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 564         |\n",
      "|    ep_rew_mean          | 0.0235      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023952682 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.965      |\n",
      "|    explained_variance   | -2.65       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0434     |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.0052      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 565        |\n",
      "|    ep_rew_mean          | 0.021      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 223        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 146        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01809717 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.972     |\n",
      "|    explained_variance   | 0.00803    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0147    |\n",
      "|    n_updates            | 3910       |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    value_loss           | 0.0236     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 565         |\n",
      "|    ep_rew_mean          | 0.0206      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038839675 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00761    |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 0.0548      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 565         |\n",
      "|    ep_rew_mean          | 0.0206      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030572468 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0697     |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.0215      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 565        |\n",
      "|    ep_rew_mean          | 0.0203     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 223        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 160        |\n",
      "|    total_timesteps      | 35840      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03148023 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0.705      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0536    |\n",
      "|    n_updates            | 3940       |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.00914    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 566         |\n",
      "|    ep_rew_mean          | 0.0184      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037826717 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0422     |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 0.00884     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 565         |\n",
      "|    ep_rew_mean          | 0.0214      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030763082 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0377     |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.0373      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 565         |\n",
      "|    ep_rew_mean          | 0.0214      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037416346 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.941      |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0136     |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.0511      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 565         |\n",
      "|    ep_rew_mean          | 0.0214      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024392966 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0414     |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 0.00899     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 576        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 40000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03234803 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | -0.35      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0236    |\n",
      "|    n_updates            | 3990       |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    value_loss           | 0.00837    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 564      |\n",
      "|    ep_rew_mean     | 0.025    |\n",
      "| time/              |          |\n",
      "|    fps             | 222      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 183      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 558         |\n",
      "|    ep_rew_mean          | 0.0353      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031662323 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0283     |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.0835      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 558        |\n",
      "|    ep_rew_mean          | 0.0353     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 225        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 191        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03268946 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.99      |\n",
      "|    explained_variance   | 0.24       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.014      |\n",
      "|    n_updates            | 4010       |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    value_loss           | 0.116      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 558        |\n",
      "|    ep_rew_mean          | 0.0353     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 225        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 194        |\n",
      "|    total_timesteps      | 44032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03415075 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.24       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0756    |\n",
      "|    n_updates            | 4020       |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.0178     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 558         |\n",
      "|    ep_rew_mean          | 0.0348      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034214623 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.606      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00885    |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.0154      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 559         |\n",
      "|    ep_rew_mean          | 0.0326      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025268627 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.028       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0378     |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.0124      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 560        |\n",
      "|    ep_rew_mean          | 0.0318     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 228        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 206        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03182315 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | -0.284     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0434    |\n",
      "|    n_updates            | 4050       |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    value_loss           | 0.0541     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 554         |\n",
      "|    ep_rew_mean          | 0.0415      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037893064 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.995      |\n",
      "|    explained_variance   | 0.0121      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0603     |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.0251      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 554         |\n",
      "|    ep_rew_mean          | 0.0415      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033119127 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.867      |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00897    |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 0.0553      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.02 +/- 0.04\n",
      "Episode length: 576.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 576        |\n",
      "|    mean_reward          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 50000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05714836 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.914     |\n",
      "|    explained_variance   | -0.16      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.00239    |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | -0.0223    |\n",
      "|    value_loss           | 0.0101     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 555      |\n",
      "|    ep_rew_mean     | 0.0405   |\n",
      "| time/              |          |\n",
      "|    fps             | 223      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 224      |\n",
      "|    total_timesteps | 50176    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 556         |\n",
      "|    ep_rew_mean          | 0.0383      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015365738 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | -0.205      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0537     |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.0261      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 556        |\n",
      "|    ep_rew_mean          | 0.0379     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 223        |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 233        |\n",
      "|    total_timesteps      | 52224      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04470501 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.355      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0549    |\n",
      "|    n_updates            | 4100       |\n",
      "|    policy_gradient_loss | -0.0415    |\n",
      "|    value_loss           | 0.0414     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 556         |\n",
      "|    ep_rew_mean          | 0.0379      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036409937 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0401     |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.0321      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 556         |\n",
      "|    ep_rew_mean          | 0.0374      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022730686 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.00296     |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 0.0165      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 557        |\n",
      "|    ep_rew_mean          | 0.0355     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 224        |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 246        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03029028 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | 0.075      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0201    |\n",
      "|    n_updates            | 4130       |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    value_loss           | 0.0157     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 557        |\n",
      "|    ep_rew_mean          | 0.0352     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 224        |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 250        |\n",
      "|    total_timesteps      | 56320      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09306673 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.0769     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0713    |\n",
      "|    n_updates            | 4140       |\n",
      "|    policy_gradient_loss | -0.0382    |\n",
      "|    value_loss           | 0.0494     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 558         |\n",
      "|    ep_rew_mean          | 0.0348      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038077816 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.00197     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0578     |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.0259      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 556         |\n",
      "|    ep_rew_mean          | 0.0386      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024346199 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0432     |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.0158      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 554        |\n",
      "|    ep_rew_mean          | 0.0426     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 225        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 263        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04192319 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.305      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0877     |\n",
      "|    n_updates            | 4170       |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.064      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.21 +/- 0.29\n",
      "Episode length: 464.60 +/- 155.06\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 465        |\n",
      "|    mean_reward          | 0.214      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 60000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03129115 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.36       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0428    |\n",
      "|    n_updates            | 4180       |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.064      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 549      |\n",
      "|    ep_rew_mean     | 0.0505   |\n",
      "| time/              |          |\n",
      "|    fps             | 221      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 272      |\n",
      "|    total_timesteps | 60416    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 547         |\n",
      "|    ep_rew_mean          | 0.0555      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029990375 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.961      |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.046      |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.0504      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 547         |\n",
      "|    ep_rew_mean          | 0.0555      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036361426 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.036      |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.0704      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 547         |\n",
      "|    ep_rew_mean          | 0.0555      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017346647 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.985      |\n",
      "|    explained_variance   | -0.315      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0413     |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.0162      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 547         |\n",
      "|    ep_rew_mean          | 0.0555      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024626223 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.0769      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00733    |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 0.0239      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 542        |\n",
      "|    ep_rew_mean          | 0.065      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 222        |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 294        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03092667 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | -0.364     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0366    |\n",
      "|    n_updates            | 4230       |\n",
      "|    policy_gradient_loss | -0.0433    |\n",
      "|    value_loss           | 0.0224     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 542         |\n",
      "|    ep_rew_mean          | 0.065       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037347764 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0175     |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 0.0934      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 542        |\n",
      "|    ep_rew_mean          | 0.065      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 222        |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 303        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02242143 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | -0.591     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0211     |\n",
      "|    n_updates            | 4250       |\n",
      "|    policy_gradient_loss | -0.0293    |\n",
      "|    value_loss           | 0.0296     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 542         |\n",
      "|    ep_rew_mean          | 0.065       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035098173 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0703     |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.0118      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 542         |\n",
      "|    ep_rew_mean          | 0.065       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026029512 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -0.501      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0789     |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 0.0101      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 576         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036764663 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | -0.335      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0398     |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 0.0482      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 542      |\n",
      "|    ep_rew_mean     | 0.065    |\n",
      "| time/              |          |\n",
      "|    fps             | 220      |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 320      |\n",
      "|    total_timesteps | 70656    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 539         |\n",
      "|    ep_rew_mean          | 0.0713      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033293396 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.343      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00934    |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 0.0249      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 539         |\n",
      "|    ep_rew_mean          | 0.0713      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028678315 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00394    |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 0.0463      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 539         |\n",
      "|    ep_rew_mean          | 0.0713      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023612116 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | -0.126      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0041     |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.0281      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 539        |\n",
      "|    ep_rew_mean          | 0.0713     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 222        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 335        |\n",
      "|    total_timesteps      | 74752      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04286453 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | -0.98      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.028     |\n",
      "|    n_updates            | 4320       |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 0.0239     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 539         |\n",
      "|    ep_rew_mean          | 0.0713      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044350103 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0828      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0442     |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 0.0425      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 536         |\n",
      "|    ep_rew_mean          | 0.0763      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 342         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040319342 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0161     |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 0.0267      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 534         |\n",
      "|    ep_rew_mean          | 0.0802      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050149523 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00246    |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.0681      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 534         |\n",
      "|    ep_rew_mean          | 0.0802      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041754466 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0221     |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 0.0322      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 536         |\n",
      "|    ep_rew_mean          | 0.0772      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026264515 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00596    |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 0.0216      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.05 +/- 0.10\n",
      "Episode length: 557.80 +/- 36.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 558         |\n",
      "|    mean_reward          | 0.0484      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029495284 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.0691      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0454     |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.0234      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 536      |\n",
      "|    ep_rew_mean     | 0.0772   |\n",
      "| time/              |          |\n",
      "|    fps             | 223      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 361      |\n",
      "|    total_timesteps | 80896    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 532         |\n",
      "|    ep_rew_mean          | 0.0836      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019664275 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0371     |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 0.0299      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 532         |\n",
      "|    ep_rew_mean          | 0.0836      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040204242 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0512     |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 0.0612      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | 0.0748      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032219253 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.0224      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | 0.0748      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040785793 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0415     |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 0.027       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | 0.0748      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025308184 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 0.0328      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | 0.0748      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039251536 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0562     |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 0.0195      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | 0.0748      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028760837 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0316     |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 0.0385      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 534         |\n",
      "|    ep_rew_mean          | 0.0799      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035146926 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | -0.0968     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.009       |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.0317      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.06 +/- 0.11\n",
      "Episode length: 553.20 +/- 45.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 553        |\n",
      "|    mean_reward          | 0.0556     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 90000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03116682 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0104    |\n",
      "|    n_updates            | 4470       |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 0.0865     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 534      |\n",
      "|    ep_rew_mean     | 0.0799   |\n",
      "| time/              |          |\n",
      "|    fps             | 225      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 398      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 534         |\n",
      "|    ep_rew_mean          | 0.0799      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026412632 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | -0.0988     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.000141   |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.0344      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 534        |\n",
      "|    ep_rew_mean          | 0.0799     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 226        |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 406        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03528715 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | 0.472      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0549    |\n",
      "|    n_updates            | 4490       |\n",
      "|    policy_gradient_loss | -0.0417    |\n",
      "|    value_loss           | 0.0349     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 536         |\n",
      "|    ep_rew_mean          | 0.0749      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024105221 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0594     |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.0468      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 536        |\n",
      "|    ep_rew_mean          | 0.0749     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 227        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 413        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05151216 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.717      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0454    |\n",
      "|    n_updates            | 4510       |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.017      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 536         |\n",
      "|    ep_rew_mean          | 0.0749      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029327253 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0259     |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.0348      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 536         |\n",
      "|    ep_rew_mean          | 0.0749      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037369348 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0744     |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 0.0402      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 540        |\n",
      "|    ep_rew_mean          | 0.0698     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 228        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 425        |\n",
      "|    total_timesteps      | 97280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03272215 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | -0.323     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0601    |\n",
      "|    n_updates            | 4540       |\n",
      "|    policy_gradient_loss | -0.0516    |\n",
      "|    value_loss           | 0.0448     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 535        |\n",
      "|    ep_rew_mean          | 0.0788     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 429        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03259951 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.523      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0263    |\n",
      "|    n_updates            | 4550       |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.0537     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 535         |\n",
      "|    ep_rew_mean          | 0.0788      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027905248 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.975      |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00187    |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.0625      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.12 +/- 0.24\n",
      "Episode length: 511.60 +/- 128.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 512         |\n",
      "|    mean_reward          | 0.121       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037373267 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0683     |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 0.0364      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 535      |\n",
      "|    ep_rew_mean     | 0.0788   |\n",
      "| time/              |          |\n",
      "|    fps             | 226      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 443      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Saving to logs/ppo/MiniGrid-BlockedUnlockPickup-v0_7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-BlockedUnlockPickup-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-UnlockPickup-v0_4/best_model.zip \\\n",
    "    --conf-file reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 279, in <module>\r\n",
      "    train()\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 192, in train\r\n",
      "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\r\n",
      "AssertionError: The trained_agent must be a valid path to a .zip file\r\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-BlockedUnlockPickup-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-BlockedUnlockPickup-v0_1/best_model.zip \\\n",
    "    --conf-file reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 279, in <module>\r\n",
      "    train()\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 192, in train\r\n",
      "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\r\n",
      "AssertionError: The trained_agent must be a valid path to a .zip file\r\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-BlockedUnlockPickup-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-BlockedUnlockPickup-v0_2/best_model.zip \\\n",
    "    --conf-file reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 279, in <module>\r\n",
      "    train()\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 192, in train\r\n",
      "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\r\n",
      "AssertionError: The trained_agent must be a valid path to a .zip file\r\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-BlockedUnlockPickup-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-BlockedUnlockPickup-v0_3/best_model.zip \\\n",
    "    --conf-file reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 279, in <module>\r\n",
      "    train()\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 192, in train\r\n",
      "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\r\n",
      "AssertionError: The trained_agent must be a valid path to a .zip file\r\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-BlockedUnlockPickup-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-BlockedUnlockPickup-v0_4/best_model.zip \\\n",
    "    --conf-file reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 279, in <module>\r\n",
      "    train()\r\n",
      "  File \"/Users/rjy/anaconda3/lib/python3.11/site-packages/rl_zoo3/train.py\", line 192, in train\r\n",
      "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\r\n",
      "AssertionError: The trained_agent must be a valid path to a .zip file\r\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to solve the task\n",
    "! python -m rl_zoo3.train --algo ppo --env MiniGrid-BlockedUnlockPickup-v0 \\\n",
    "    --eval-freq 10000 \\\n",
    "    --trained-agent logs/ppo/MiniGrid-BlockedUnlockPickup-v0_5/best_model.zip \\\n",
    "    --conf-file reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ENe5lnAiRKeR"
   },
   "outputs": [],
   "source": [
    "third_task = gym.make(\"MiniGrid-BlockedUnlockPickup-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "_fAy3slmRGDa"
   },
   "outputs": [],
   "source": [
    "from wrappers import DiscreteObsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "third_env = DiscreteObsWrapper(third_task)\n",
    "third_model = PPO.load(\"logs/ppo/MiniGrid-BlockedUnlockPickup-v0_6/best_model.zip\")\n",
    "\n",
    "def third_policy(observation):\n",
    "  observation = third_env.observation(observation)\n",
    "  action, _ = third_model.predict(observation)\n",
    "    \n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ehJfJhlnRcx6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.758\n",
      "Average score: (0.223, 0.341)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00, 0.00, 0.00, 0.76, 0.00, 0.73, 0.00, 0.75, 0.00, 0.00])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(task=third_task, policy=third_policy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
